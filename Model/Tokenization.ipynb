{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "103f28a8-b3cf-4871-ac7e-8882f76e514c",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67c8028-99ca-4aed-8c17-5e8b4a2cde35",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9295f902-75db-4028-b7aa-78702482202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/L1.txt\") as f:\n",
    "    L1 = f.read()\n",
    "data = L1[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91810e51-7aab-4393-93e8-ecc91d07088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Alice's Adventures in Wonderland\n",
      "Author: Lewis Carroll\n",
      "Release date: June 27, 2008 [eBook #11]\n",
      "                Most recently updated: November 10, 2024\n",
      "Language: English\n",
      "Credits: Arthur DiBianc\n"
     ]
    }
   ],
   "source": [
    "print(data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f974a498-ec91-4b51-a3fa-29e6ae96a62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14871952\n"
     ]
    }
   ],
   "source": [
    "print(len(L1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc1d34cd-f541-4918-9c0d-11fa5c70c263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a22bd948-ec3c-40a0-82b3-729b7c9d9d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/L2.txt\") as f:\n",
    "    L2 = f.read()\n",
    "data2 = L2[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46cea290-e1cf-412b-a73c-47a778f0eaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25930805\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(L2))\n",
    "print(len(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6a3793d-442c-4f83-b1d4-5bf9f32f5fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Book 1 ===\n",
      "The Declaration of Independence Of the United States Of America,\n",
      "===========================================================\n",
      "\n",
      "     NOTE:  This file combines the first two Project Gutenb\n"
     ]
    }
   ],
   "source": [
    "print(data2[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c9f878f-dee3-473e-9cb7-8c8548d44bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/L3.txt\") as f:\n",
    "    L3 = f.read()\n",
    "data3 = L3[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d1ab98f-bf6a-451a-aa74-4db2efd16371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26206426\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(L3))\n",
    "print(len(data3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90bc588a-0578-4f33-949c-d1f213fc2ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://www.bbc.com/news/topics/c2vdnvdg6xxt\n",
      "Palestinian paramedic Munther Abed rejects Israel's assertion that the vehicles approached troops with their lights off.\n",
      "Many Palestinians say they ar\n"
     ]
    }
   ],
   "source": [
    "print(data3[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57bb272b-6228-45ec-8e52-c539cffae7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/L4.txt\") as f:\n",
    "    L4 = f.read()\n",
    "data4 = L4[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c05cd9c-3780-412e-8ee6-66cb0f2e264f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18896924\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(L4))\n",
    "print(len(data4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1515d888-99c2-45e0-b1fa-275963a44244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== The LLM Wears Prada: Analysing Gender Bias and Stereotypes through Online Shopping Data ===\n",
      "Authors: Massimiliano Luca, Ciro Beneduce, Bruno Lepri, Jacopo Staiano\n",
      "Published: 2025-04-02\n",
      "URL: http:/\n"
     ]
    }
   ],
   "source": [
    "print(data4[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b106a90-cadc-4327-8c9e-9882dec568b1",
   "metadata": {},
   "source": [
    "## EDA on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f8a78ff-2a3e-4f79-9ce8-306047c0b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_l1 = sorted(list(set(L1)))\n",
    "vocab_size_l1 = len(chars_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1def8b8-7a73-47be-b409-e602c9aa6dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      "\t\n",
      " !\"#$&'()*,-./0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_`abcdefghijklmnopqrstuvwxyz{} ¦°ÃÆÉàâäæçèéêïñòôöøùüœαβ–—‘’“”′″\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size_l1)\n",
    "print(''.join(chars_l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b98c50f-f6c2-4596-9e4a-150a8a92d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_l2 = sorted(list(set(L2)))\n",
    "vocab_size_l2 = len(chars_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbaa6dce-921c-45c4-9807-0b5f145fc69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n",
      "\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ £Æ×àáâäåæçèéêëíïñóôöùûüāŒœΑΛΤΦέίαβγεηικλμνξοπρςστυωόύϰוחἰὁᾶ–—‘’“”…′\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size_l2)\n",
    "print(''.join(chars_l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1be6453c-5239-44b4-8635-82075595fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_l3 = sorted(list(set(L3)))\n",
    "vocab_size_l3 = len(chars_l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9866d217-e587-4dd1-8bcc-b82f5336c923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      "\n",
      " \"$%&'(),-./0123456789:=?ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz£É’…\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size_l3)\n",
    "print(''.join(chars_l3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5b22302-8f0c-46f6-a25d-5d2887a73f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_l4 = sorted(list(set(L4)))\n",
    "vocab_size_l4 = len(chars_l4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05c3a733-4539-47b0-9d9f-abe33ef5a33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1745\n",
      "\u0000\t\n",
      "\u000b",
      "\f",
      "\u000f\u0010\u0011\u0012\u0013\u0014\u0015\u0016\u0017\u0018\u0019\u001a\u001b\u001c",
      "\u001d",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ ¡¢£¥§¨©«¬­®¯°±²³´µ¶·¸¹º»¿ÀÁÂÄÅÇÉÍÐÓÔÖ×ØÚÜßàáâãäåæçèéêëìíïñòóôõöøùúüýÿăąćČčďęěğıĳŁłńňŒřśŞŠšţźżŽžƒǫˆˇˋ˘˙˚˛˜˝̸̂ΓΔΕΘΙΚΛΠΣΤΥΦΧΨΩήίαβγδεζηθικλμνξοπρςστυφχψωόύώϕϵПЧЪабвгдежзийклмнопрстуцчшыьєїاروڑیंइऔकगघजटठडतदधनपफबमयरलवसहाुेैॉोड़फ़।ংঅআউএকখগচটডতদধনবমযরহািুূে্ਂਅਓਕਗਚਜਟਣਤਦਧਨਪਫਬਮਰਲਵਸ਼ਸਹਾਿੀੁੂੇੈੋੱంఇఉఎకగచటడతదధనబమయరలవశసాిీుూేో్ขคงณดตทนบปผยรลวสหอะัำีุเแโใไ่้ᄀᄂᄃᄅᄇᄉᄋᄌᄏᄐᄑ하ᅢᅥᅩᅪᅬᅮᅳᅵᆨᆫᆯᆻᆼ  ​‌‐–—‘’‚“”„†‡•… ",
      " ‰′‹€⃗⃝ℎℒℓℕℝ™ℱℳⅠⅡⅢⅳ←↑→↓↔↦↾⇐⇒⇓⇔∀∂∃∅∆∇∈∏∑−∗√∝∞∥∧∨∩∪∫∶∼≃≈≜≠≡≤≥≦≪≫≺≻⊂⊆⊓⊔⊕⊗⊙⊛⊢⊣⊤⊥⊲⋄⋅⋆⋉⋯⌈⌉⌊⌋⌢〉⎡⎣⎤⎦⎧⎨⎩⎪␣①②③④⑤⑥⑦⑧⑨■□▲△▶▷◇●◦♠♡♢♣♦♭♮✅✓✔✗✘✦❌❓❶❷❸❹❺❻⟨⟩⨁⩾、。《》【】いうえおがくこさしすただちつてでとなにのまもよらるをアィウスツデブメラㄴㄹ一万三上下不与丑专且世业东两严个中丹为主么义之也习书买乱了二于互五亚些交亮亲人什仅从他代以们价任份优会传但位住体何余作你使來例供保信個們候假做像儿元先克免兒入全公六共其典内再冗写军冠冬冰决况准凉出刀分切划则创判別利别到刷刺剂剃前剛剩副力功加动助勇化医十升单卖南博危即历原去又及友反发取变句另只召可台史号各合同名后向吗否吧含吸呀呃周命和咧品哎哥哧哪唱商問善喜嘛四回因国图圈國在地场均坐城基報境增墨士处复外多大天太央奇奏奖女她好如妙妨妹始姐委子字存学孩學它宇安完官宙定实客害家宾察實对對小少尝就层居展属山崇州工差己已巴巾币市帅师希带師帮常干平年并幸幹序应底店度开式引张弱当形影往很後得循微德必忐忑志忙快怕思性怪总息恼您情惊想愈意感慢慰慶懈應戏成我或所手才扑打托找承把抱抽拙招择拿按挽据接推提握搅搜搭携摊撒放政效敬数整文料断斯新方旅无日旦早时明星春是時晒暗最會月有朋望木未本术机权材束条来松极构析林果枯染标校样根格案森樣横機橡橱次欧歉歌正此步歩殉残段母每比毛气水求江污汰汽没河治法波泥泳泼洒洲活流浆消淘混渐渡港游湖溅源漾激火灵炉炮点為烟烦热然照爱父爸片版牙物特独率玩环现球理瓜生用由电画畏當疑疾病的皮益盐目直相盾看真着睡矛知石破硝硬确碰示社祝神福离种科秘程稍稿空立笔符第答策签简算箱篇精系索終結纠红级纪纷织终经结绕给绝统缠缺网罗置美老考者而耗耽职联背胳胶能脑脚脸膊臂自致興舞航般船花芽英茶荐荡药获菜菱萌著葱虽行表被装裡裨西要覺观视觉解觸言話該認論警變讓计认让讪议记讶论证评识词试话该语误说请读谈谜质贴费资赫走起超越趟趣足跑距跟路身车载辆辑输达过近返还这进远述适选逐递這通速造逻遇過道遵避還邊那邻部都配酸里重量金钟铅错镇镜长问间闻防阴阿际陈陌階难雪電需青静非面鞭音題類须频题飞馆首马验高魂魄鲜麦麻麼點龙가간갖개건게계고국그까나내너넌널년노누는다단덧도되등디때란람랑러로르를리마말면명무물보부북불붙빠사상생서섰세셔수스시식실싶아어업었에엘엠여오용우웅원월은을의이익인일입있자장저적제좌지직초치칙테통트파페프하학한할횡車不參說了樂理ﬀﬁﬂﬃﬄﭘﮑﮔﮕﮧﮨﮯﯽﯾﯿ︀︁︂︃️ﺎﺗﺘﺪﺲﺳﺷﻞﻟﻮ！（），．：；？�𝐲𝐴𝐵𝐶𝐷𝐸𝐹𝐺𝐻𝐼𝐾𝐿𝑀𝑁𝑂𝑃𝑄𝑅𝑆𝑇𝑈𝑉𝑊𝑋𝑌𝑍𝑎𝑏𝑐𝑑𝑒𝑓𝑔𝑖𝑗𝑘𝑙𝑚𝑛𝑜𝑝𝑞𝑟𝑠𝑡𝑢𝑣𝑤𝑥𝑦𝑧𝑨𝑩𝑪𝑬𝑲𝑴𝑵𝑷𝑹𝑼𝑾𝑿𝒀𝒂𝒃𝒄𝒅𝒌𝒍𝒓𝒔𝒕𝒙𝒜𝒟𝒢𝒩𝒮𝒱𝒳𝓋𝔰𝔼𝙺𝙽𝙾𝚀𝚃𝚅𝚆𝚍𝛼𝛽𝛾𝛿𝜀𝜂𝜃𝜆𝜇𝜈𝜋𝜌𝜎𝜏𝜒𝜓𝜔𝜖𝜙𝜶𝝀𝝉𝝏𝝐𝞓𝟎𝟏𝟐𝟑𝟶𝟷𝟸𝟹𝟺𝟽𝟿💊🔥😡🤬\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size_l4)\n",
    "print(''.join(chars_l4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2b5e4cf-5d84-47d8-8086-c0e5b2e542b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ L4 cleaned and stored in L4_cleaned!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import emoji\n",
    "\n",
    "# Define allowed character sets\n",
    "english_regex = r\"[a-zA-Z0-9\\s]\"  # English letters, numbers, spaces\n",
    "math_symbols = r\"[\\+\\-\\*/=<>∑∫√πθΣ∂∞]\"  # Add more math symbols if needed\n",
    "special_chars = r\"[\\.,!?;:'\\\"()\\[\\]{}#@%^&*_~]\"  # Common special chars\n",
    "\n",
    "# Function to keep only emojis\n",
    "def keep_emojis(text):\n",
    "    return \"\".join(c for c in text if emoji.is_emoji(c))\n",
    "\n",
    "# Remove non-English, non-math, non-special, and non-emoji characters\n",
    "L4_cleaned = \"\".join(\n",
    "    c for c in L4 if re.match(english_regex, c) or \n",
    "                    re.match(math_symbols, c) or \n",
    "                    re.match(special_chars, c) or \n",
    "                    emoji.is_emoji(c)\n",
    ")\n",
    "\n",
    "# Now, L4_cleaned holds the cleaned version of L4\n",
    "print(\"✅ L4 cleaned and stored in L4_cleaned!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e5c47ac-fc52-4d7c-9b08-e3a552d6bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_l4 = sorted(list(set(L4_cleaned)))\n",
    "vocab_size_l4 = len(chars_l4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6c1a9b3-364e-4dac-b6eb-c86966affbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n",
      "\t\n",
      "\u000b",
      "\f",
      "\u001c",
      "\u001d",
      " !\"#%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^_abcdefghijklmnopqrstuvwxyz{}~ ©®Σθπ   ",
      " ™↔∂∑√∞∫▶♠♣♦✅✔❌❓💊🔥😡🤬\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size_l4)\n",
    "print(''.join(chars_l4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e254296f-5fd4-4178-9e74-deae485c58a3",
   "metadata": {},
   "source": [
    "## Tokenizing as charaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d38ec12-f010-4c51-8aa3-f69d3772edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi_l1 = { ch:i for i,ch in enumerate(chars_l1) }\n",
    "itos_l1 = { i:ch for i,ch in enumerate(chars_l1) }\n",
    "encode_l1 = lambda s: [stoi_l1[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode_l1 = lambda l: ''.join([itos_l1[i] for i in l]) # decoder: take a list of integers, output a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28e91a47-e197-4614-9abc-83b774a4e152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37, 68, 68, 2, 3, 3, 2, 37, 74, 82, 2, 60, 77, 64, 2, 84, 74, 80]\n"
     ]
    }
   ],
   "source": [
    "print(encode_l1(\"Hii !! How are you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c684ade9-f6a2-42e9-af48-6445273e8b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hii !! How are you\n"
     ]
    }
   ],
   "source": [
    "print(decode_l1([37, 68, 68, 2, 3, 3, 2, 37, 74, 82, 2, 60, 77, 64, 2, 84, 74, 80]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "307f4655-3e93-41dd-9b14-d1bcb06a6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi_l2 = { ch:i for i,ch in enumerate(chars_l2) }\n",
    "itos_l2 = { i:ch for i,ch in enumerate(chars_l2) }\n",
    "encode_l2 = lambda s: [stoi_l2[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode_l2 = lambda l: ''.join([itos_l2[i] for i in l]) # decoder: take a list of integers, output a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67bfecc5-e353-4d16-8f93-dd544bc6892d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41, 74, 74, 1, 2, 2, 1, 41, 80, 88, 1, 66, 83, 70, 1, 90, 80, 86]\n"
     ]
    }
   ],
   "source": [
    "print(encode_l2(\"Hii !! How are you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9dccde12-e372-48b6-88ba-476317834b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hii !! How are you\n"
     ]
    }
   ],
   "source": [
    "print(decode_l2([41, 74, 74, 1, 2, 2, 1, 41, 80, 88, 1, 66, 83, 70, 1, 90, 80, 86]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02562007-3378-4e75-8324-1a8961734982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi_l3 = { ch:i for i,ch in enumerate(chars_l3) }\n",
    "itos_l3 = { i:ch for i,ch in enumerate(chars_l3) }\n",
    "encode_l3 = lambda s: [stoi_l3[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode_l3 = lambda l: ''.join([itos_l3[i] for i in l]) # decoder: take a list of integers, output a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd600da4-c6d0-41ca-84d1-d6afae8f4ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33, 61, 61, 1, 33, 67, 75, 1, 53, 70, 57, 1, 77, 67, 73, 1, 52, 52, 52, 60, 72, 72, 68, 71, 12, 12]\n"
     ]
    }
   ],
   "source": [
    "print(encode_l3(\"Hii How are you ___https//\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "353b6945-0106-4de8-bf78-1e1985e7c543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hii How are you ___https//\n"
     ]
    }
   ],
   "source": [
    "print(decode_l3([33, 61, 61, 1, 33, 67, 75, 1, 53, 70, 57, 1, 77, 67, 73, 1, 52, 52, 52, 60, 72, 72, 68, 71, 12, 12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6427801-a843-4f4d-b762-4e95b0e64a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi_l4 = { ch:i for i,ch in enumerate(chars_l4) }\n",
    "itos_l4 = { i:ch for i,ch in enumerate(chars_l4) }\n",
    "encode_l4 = lambda s: [stoi_l4[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode_l4 = lambda l: ''.join([itos_l4[i] for i in l]) # decoder: take a list of integers, output a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35c782b8-2a64-4f9b-a71d-0a0cea5a9858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45, 76, 76, 6, 18, 7, 7, 6, 45, 82, 90, 6, 68, 85, 72, 6, 92, 82, 88, 6, 123]\n"
     ]
    }
   ],
   "source": [
    "print(encode_l4(\"Hii -!! How are you 🔥\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4b5d4535-a846-4abc-9d81-d79c5ba089b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hii -!! How are you 🔥\n"
     ]
    }
   ],
   "source": [
    "print(decode_l4([45, 76, 76, 6, 18, 7, 7, 6, 45, 82, 90, 6, 68, 85, 72, 6, 92, 82, 88, 6, 123]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4a678a-2c4f-42fd-81c4-41854f647bbd",
   "metadata": {},
   "source": [
    "## Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db237f5c-0485-497f-bfe8-99d4d3e02b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eab9683d-a1a5-4035-afc9-6d4517286653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test splits\n",
    "data_l1 = torch.tensor(encode_l1(L1), dtype=torch.long)\n",
    "n = int(0.9*len(data_l1)) # first 90% will be train, rest val\n",
    "train_data_l1 = data_l1[:n]\n",
    "val_data_l1 = data_l1[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed6476d0-3fe1-4135-822d-1e8ababe701c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14871952]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(data_l1.shape,data_l1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53f948c9-3754-42fc-9275-d68030a40863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 49,  68,  79,  71,  64,  26,   2,  30,  71,  68,  62,  64,   8,  78,\n",
      "          2,  30,  63,  81,  64,  73,  79,  80,  77,  64,  78,   2,  68,  73,\n",
      "          2,  52,  74,  73,  63,  64,  77,  71,  60,  73,  63,   1,  30,  80,\n",
      "         79,  67,  74,  77,  26,   2,  41,  64,  82,  68,  78,   2,  32,  60,\n",
      "         77,  77,  74,  71,  71,   1,  47,  64,  71,  64,  60,  78,  64,   2,\n",
      "         63,  60,  79,  64,  26,   2,  39,  80,  73,  64,   2,  18,  23,  12,\n",
      "          2,  18,  16,  16,  24,   2,  56,  64,  31,  74,  74,  70,   2,   5,\n",
      "         17,  17,  57,   1,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "          2,   2,   2,   2,   2,   2,  42,  74,  78,  79,   2,  77,  64,  62,\n",
      "         64,  73,  79,  71,  84,   2,  80,  75,  63,  60,  79,  64,  63,  26,\n",
      "          2,  43,  74,  81,  64,  72,  61,  64,  77,   2,  17,  16,  12,   2,\n",
      "         18,  16,  18,  20,   1,  41,  60,  73,  66,  80,  60,  66,  64,  26,\n",
      "          2,  34,  73,  66,  71,  68,  78,  67,   1,  32,  77,  64,  63,  68,\n",
      "         79,  78,  26,   2,  30,  77,  79,  67,  80,  77,   2,  33,  68,  31,\n",
      "         68,  60,  73,  62,  60,   2,  60,  73,  63,   2,  33,  60,  81,  68,\n",
      "         63,   2,  52,  68,  63,  66,  64,  77,   1,   1,  30,  71,  68,  62,\n",
      "         64,   2,  82,  60,  78,   2,  61,  64,  66,  68,  73,  73,  68,  73,\n",
      "         66,   2,  79,  74,   2,  66,  64,  79,   2,  81,  64,  77,  84,   2,\n",
      "         79,  68,  77,  64,  63,   2,  74,  65,   2,  78,  68,  79,  79,  68,\n",
      "         73,  66,   2,  61,  84,   2,  67,  64,  77,   2,  78,  68,  78,  79,\n",
      "         64,  77,   2,  74,  73,   2,  79,  67,  64,   2,  61,  60,  73,  70,\n",
      "         12,   2,  60,  73,  63,   1,  74,  65,   2,  67,  60,  81,  68,  73,\n",
      "         66,   2,  73,  74,  79,  67,  68,  73,  66,   2,  79,  74,   2,  63,\n",
      "         74,  26,   2,  74,  73,  62,  64,   2,  74,  77,   2,  79,  82,  68,\n",
      "         62,  64,   2,  78,  67,  64,   2,  67,  60,  63,   2,  75,  64,  64,\n",
      "         75,  64,  63,   2,  68,  73,  79,  74,   2,  79,  67,  64,   2,  61,\n",
      "         74,  74,  70,   2,  67,  64,  77,   2,  78,  68,  78,  79,  64,  77,\n",
      "          1,  82,  60,  78,   2,  77,  64,  60,  63,  68,  73,  66,  12,   2,\n",
      "         61,  80,  79,   2,  68,  79,   2,  67,  60,  63,   2,  73,  74,   2,\n",
      "         75,  68,  62,  79,  80,  77,  64,  78,   2,  74,  77,   2,  62,  74,\n",
      "         73,  81,  64,  77,  78,  60,  79,  68,  74,  73,  78,   2,  68,  73,\n",
      "          2,  68,  79,  12,   2, 118,  60,  73,  63,   2,  82,  67,  60,  79,\n",
      "          2,  68,  78,   1,  79,  67,  64,   2,  80,  78,  64,   2,  74,  65,\n",
      "          2,  60,   2,  61,  74,  74,  70,  12, 119,   2,  79,  67,  74,  80,\n",
      "         66,  67,  79,   2,  30,  71,  68,  62,  64,   2, 118,  82,  68,  79,\n",
      "         67,  74,  80,  79,   2,  75,  68,  62,  79,  80])\n"
     ]
    }
   ],
   "source": [
    "print(data_l1[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "01ad47f8-3e2e-4578-a95e-40f7c50768ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test splits\n",
    "data_l2 = torch.tensor(encode_l2(L2), dtype=torch.long)\n",
    "n = int(0.9*len(data_l2)) # first 90% will be train, rest val\n",
    "train_data_l2 = data_l2[:n]\n",
    "val_data_l2 = data_l2[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a0adfad-818b-45de-aade-f2a83231e04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25930805]) torch.int64\n",
      "tensor([30, 30, 30,  1, 35, 80, 80, 76,  1, 18,  1, 30, 30, 30,  0, 53, 73, 70,\n",
      "         1, 37, 70, 68, 77, 66, 83, 66, 85, 74, 80, 79,  1, 80, 71,  1, 42, 79,\n",
      "        69, 70, 81, 70, 79, 69, 70, 79, 68, 70,  1, 48, 71,  1, 85, 73, 70,  1,\n",
      "        54, 79, 74, 85, 70, 69,  1, 52, 85, 66, 85, 70, 84,  1, 48, 71,  1, 34,\n",
      "        78, 70, 83, 74, 68, 66, 13,  0, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
      "        30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
      "        30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
      "        30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,  0,  0,  1,  1,  1,\n",
      "         1,  1, 47, 48, 53, 38, 27,  1,  1, 53, 73, 74, 84,  1, 71, 74, 77, 70,\n",
      "         1, 68, 80, 78, 67, 74, 79, 70, 84,  1, 85, 73, 70,  1, 71, 74, 83, 84,\n",
      "        85,  1, 85, 88, 80,  1, 49, 83, 80, 75, 70, 68, 85,  1, 40, 86, 85, 70,\n",
      "        79, 67, 70, 83, 72,  0,  1,  1,  1,  1,  1, 71, 74, 77, 70, 84, 13,  1,\n",
      "        67, 80, 85, 73,  1, 80, 71,  1, 88, 73, 74, 68, 73,  1, 88, 70, 83, 70,\n",
      "         1, 72, 74, 87, 70, 79,  1, 85, 73, 70,  1, 71, 74, 77, 70, 79, 86, 78,\n",
      "        67, 70, 83,  1,  4, 18, 15,  1, 53, 73, 70, 83, 70,  1, 66, 83, 70,  0,\n",
      "         1,  1,  1,  1,  1, 84, 70, 87, 70, 83, 66, 77,  1, 69, 86, 81, 77, 74,\n",
      "        68, 66, 85, 70,  1, 71, 74, 77, 70, 84,  1, 73, 70, 83, 70, 15,  1, 53,\n",
      "        73, 70, 83, 70,  1, 88, 70, 83, 70,  1, 78, 66, 79, 90,  1, 86, 81, 69,\n",
      "        66, 85, 70, 84,  1, 80, 87, 70, 83,  0,  1,  1,  1,  1,  1, 85, 73, 70,\n",
      "         1, 90, 70, 66, 83, 84, 15,  1,  1, 34, 77, 77,  1, 80, 71,  1, 85, 73,\n",
      "        70,  1, 80, 83, 74, 72, 74, 79, 66, 77,  1, 71, 74, 77, 70, 84,  1, 66,\n",
      "        83, 70,  1, 74, 79, 68, 77, 86, 69, 70, 69,  1, 74, 79,  1, 85, 73, 70,\n",
      "         0,  1,  1,  1,  1,  1,  3, 80, 77, 69,  3,  1, 84, 86, 67, 69, 74, 83,\n",
      "        70, 68, 85, 80, 83, 90,  1, 88, 73, 74, 68, 73,  1, 78, 66, 90,  1, 67,\n",
      "        70,  1, 66, 68, 68, 70, 84, 84, 70, 69,  1, 86, 79, 69, 70, 83,  1, 85,\n",
      "        73, 70,  1,  3, 46, 80, 83, 70,  0,  1,  1,  1,  1,  1, 39, 74, 77, 70,\n",
      "        84,  3,  1, 77, 74, 84, 85, 74, 79, 72,  1, 74, 79,  1, 85, 73, 70,  1,\n",
      "        49, 40,  1, 36, 66, 85, 66, 77, 80, 72,  1, 80, 71,  1])\n"
     ]
    }
   ],
   "source": [
    "print(data_l2.shape,data_l2.dtype)\n",
    "print(data_l2[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b6a88ca6-2c24-4e50-a185-4449ed050e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test splits\n",
    "data_l3 = torch.tensor(encode_l3(L3), dtype=torch.long)\n",
    "n = int(0.9*len(data_l3)) # first 90% will be train, rest val\n",
    "train_data_l3 = data_l3[:n]\n",
    "val_data_l3 = data_l3[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "063df2f5-b671-4e3b-89ee-fd0576e5758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26206426]) torch.int64\n",
      "tensor([46, 43, 37, 23,  1, 60, 72, 72, 68, 71, 23, 12, 12, 75, 75, 75, 11, 54,\n",
      "        54, 55, 11, 55, 67, 65, 12, 66, 57, 75, 71, 12, 72, 67, 68, 61, 55, 71,\n",
      "        12, 55, 15, 74, 56, 66, 74, 56, 59, 19, 76, 76, 72,  0, 41, 53, 64, 57,\n",
      "        71, 72, 61, 66, 61, 53, 66,  1, 68, 53, 70, 53, 65, 57, 56, 61, 55,  1,\n",
      "        38, 73, 66, 72, 60, 57, 70,  1, 26, 54, 57, 56,  1, 70, 57, 62, 57, 55,\n",
      "        72, 71,  1, 34, 71, 70, 53, 57, 64,  6, 71,  1, 53, 71, 71, 57, 70, 72,\n",
      "        61, 67, 66,  1, 72, 60, 53, 72,  1, 72, 60, 57,  1, 74, 57, 60, 61, 55,\n",
      "        64, 57, 71,  1, 53, 68, 68, 70, 67, 53, 55, 60, 57, 56,  1, 72, 70, 67,\n",
      "        67, 68, 71,  1, 75, 61, 72, 60,  1, 72, 60, 57, 61, 70,  1, 64, 61, 59,\n",
      "        60, 72, 71,  1, 67, 58, 58, 11,  0, 38, 53, 66, 77,  1, 41, 53, 64, 57,\n",
      "        71, 72, 61, 66, 61, 53, 66, 71,  1, 71, 53, 77,  1, 72, 60, 57, 77,  1,\n",
      "        53, 70, 57,  1, 59, 67, 61, 66, 59,  1, 60, 73, 66, 59, 70, 77,  1, 53,\n",
      "        58, 72, 57, 70,  1, 34, 71, 70, 53, 57, 64,  1, 71, 72, 67, 68, 68, 57,\n",
      "        56,  1, 53, 64, 64,  1, 53, 61, 56,  1, 56, 57, 64, 61, 74, 57, 70, 61,\n",
      "        57, 71,  1, 72, 67,  1, 68, 73, 72,  1, 68, 70, 57, 71, 71, 73, 70, 57,\n",
      "         1, 67, 66,  1, 33, 53, 65, 53, 71, 11,  0, 34, 72,  1, 61, 71,  1, 72,\n",
      "        60, 57,  1, 54, 61, 59, 59, 57, 71, 72,  1, 71, 73, 55, 60,  1, 67, 70,\n",
      "        56, 57, 70,  1, 71, 61, 66, 55, 57,  1, 34, 71, 70, 53, 57, 64,  1, 70,\n",
      "        57, 71, 73, 65, 57, 56,  1, 61, 72, 71,  1, 67, 58, 58, 57, 66, 71, 61,\n",
      "        74, 57,  1, 61, 66,  1, 72, 60, 57,  1, 41, 53, 64, 57, 71, 72, 61, 66,\n",
      "        61, 53, 66,  1, 72, 57, 70, 70, 61, 72, 67, 70, 77,  1, 57, 53, 70, 64,\n",
      "        61, 57, 70,  1, 72, 60, 61, 71,  1, 65, 67, 66, 72, 60, 11,  0, 29, 70,\n",
      "         1, 38, 53, 70, 63,  1, 41, 57, 70, 64, 65, 73, 72, 72, 57, 70,  1, 71,\n",
      "        53, 77, 71,  1, 56, 67, 55, 72, 67, 70, 71,  1, 53, 70, 57,  1, 75, 67,\n",
      "        70, 63, 61, 66, 59,  1, 75, 61, 72, 60, 67, 73, 72,  1, 71, 67, 53, 68,\n",
      "         9,  1, 53, 66, 72, 61, 54, 61, 67, 72, 61, 55, 71,  1, 67, 70,  1, 76,\n",
      "        10, 70, 53, 77,  1, 58, 53, 55, 61, 64, 61, 72, 61, 57, 71,  9,  1, 53,\n",
      "        71,  1, 34, 71, 70, 53, 57, 64,  1, 60, 53, 71,  1, 70])\n"
     ]
    }
   ],
   "source": [
    "print(data_l3.shape,data_l3.dtype)\n",
    "print(data_l3[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6d49918c-b7e4-4738-92f1-f54514a228ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test splits\n",
    "data_l4 = torch.tensor(encode_l4(L4_cleaned), dtype=torch.long)\n",
    "n = int(0.9*len(data_l4)) # first 90% will be train, rest val\n",
    "train_data_l4 = data_l4[:n]\n",
    "val_data_l4 = data_l4[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a53987da-6de6-4402-afa9-f2050ed586a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18777665]) torch.int64\n",
      "tensor([34, 34, 34,  6, 57, 75, 72,  6, 49, 49, 50,  6, 60, 72, 68, 85, 86,  6,\n",
      "        53, 85, 68, 71, 68, 31,  6, 38, 81, 68, 79, 92, 86, 76, 81, 74,  6, 44,\n",
      "        72, 81, 71, 72, 85,  6, 39, 76, 68, 86,  6, 68, 81, 71,  6, 56, 87, 72,\n",
      "        85, 72, 82, 87, 92, 83, 72, 86,  6, 87, 75, 85, 82, 88, 74, 75,  6, 52,\n",
      "        81, 79, 76, 81, 72,  6, 56, 75, 82, 83, 83, 76, 81, 74,  6, 41, 68, 87,\n",
      "        68,  6, 34, 34, 34,  1, 38, 88, 87, 75, 82, 85, 86, 31,  6, 50, 68, 86,\n",
      "        86, 76, 80, 76, 79, 76, 68, 81, 82,  6, 49, 88, 70, 68, 17,  6, 40, 76,\n",
      "        85, 82,  6, 39, 72, 81, 72, 71, 88, 70, 72, 17,  6, 39, 85, 88, 81, 82,\n",
      "         6, 49, 72, 83, 85, 76, 17,  6, 47, 68, 70, 82, 83, 82,  6, 56, 87, 68,\n",
      "        76, 68, 81, 82,  1, 53, 88, 69, 79, 76, 86, 75, 72, 71, 31,  6, 23, 21,\n",
      "        23, 26, 18, 21, 25, 18, 21, 23,  1, 58, 55, 49, 31,  6, 75, 87, 87, 83,\n",
      "        31, 20, 20, 68, 85, 91, 76, 89, 19, 82, 85, 74, 20, 68, 69, 86, 20, 23,\n",
      "        26, 21, 25, 19, 21, 22, 30, 26, 22, 89, 22,  1,  1, 26,  6, 23,  6, 21,\n",
      "         6, 23,  1,  1, 85,  6, 83,  6, 38,  6, 23,  1,  1, 65,  6, 46,  1,  1,\n",
      "        38,  6, 19,  6, 86,  6, 70,  6, 64,  1,  1, 22,  6, 89,  6, 22,  6, 26,\n",
      "         6, 30,  6, 22,  6, 21,  6, 19,  6, 25,  6, 21,  6, 26,  6, 23,  6, 31,\n",
      "         6, 89,  6, 76,  6, 61,  6, 85,  6, 68,  1,  1, 53, 85, 72, 83, 85, 76,\n",
      "        81, 87, 19,  6, 58, 81, 71, 72, 85,  6, 85, 72, 89, 76, 72, 90, 19,  1,\n",
      "         1, 57, 75, 72,  6, 49, 49, 50,  6, 60, 72, 68, 85, 86,  6, 53, 85, 68,\n",
      "        71, 68, 31,  6, 38, 81, 68, 79, 92, 86, 76, 81, 74,  6, 44, 72, 81, 71,\n",
      "        72, 85,  6, 39, 76, 68, 86,  6, 68, 81, 71,  6, 56, 87, 72, 85, 72, 82,\n",
      "        87, 92, 83, 72, 86,  6, 87, 75, 85, 82, 88, 74, 75,  6, 52, 81, 79, 76,\n",
      "        81, 72,  6, 56, 75, 82, 83, 83, 76, 81, 74,  6, 41, 68, 87, 68,  1,  1,\n",
      "        50, 68, 86, 86, 76, 80, 76, 79, 76, 68, 81, 82,  6, 49, 88, 70, 68, 17,\n",
      "         6, 40, 76, 85, 82,  6, 39, 72, 81, 72, 71, 88, 70, 72, 17,  6, 39, 85,\n",
      "        88, 81, 82,  6, 49, 72, 83, 85, 76,  6, 50, 82, 69, 76, 79, 72,  6, 68,\n",
      "        81, 71,  6, 56, 82, 70, 76, 68, 79,  6, 40, 82, 80, 83, 88, 87, 76, 81,\n",
      "        74,  6, 49, 68, 69,  6, 13, 50, 52, 39, 56, 14,  6, 43])\n"
     ]
    }
   ],
   "source": [
    "print(data_l4.shape,data_l4.dtype)\n",
    "print(data_l4[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af92b064-ceaf-4291-99c8-bfc720a74df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
